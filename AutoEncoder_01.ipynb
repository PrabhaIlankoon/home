{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape =  (60000, 28, 28) y_train shape =  (60000,)\n",
      "x_test shape =  (10000, 28, 28) y_test shape =  (10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist #importing the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print \"x_train shape = \", x_train.shape, \"y_train shape = \", y_train.shape\n",
    "print \"x_test shape = \", x_test.shape, \"y_test shape = \", y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casting inputs to float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test  = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) => (60000, 784)\n",
      "(10000, 28, 28) => (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = 784 #28 by 28\n",
    "\n",
    "x_train_reshape = x_train.reshape(60000, INPUT_DIM)\n",
    "x_test_reshape = x_test.reshape(10000, INPUT_DIM)\n",
    "print x_train.shape, \"=>\", x_train_reshape.shape\n",
    "print x_test.shape,  \"=>\", x_test_reshape.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_reshape /= 255\n",
    "x_test_reshape  /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 784)               25872     \n",
      "=================================================================\n",
      "Total params: 50,992\n",
      "Trainable params: 50,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "ENCODING_DIM = 32\n",
    "autoencoder = Sequential()\n",
    "autoencoder.add(Dense(ENCODING_DIM, activation='relu', input_shape=(INPUT_DIM,)))\n",
    "autoencoder.add(Dense(INPUT_DIM, activation='sigmoid'))\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.3601 - acc: 0.7562 - val_loss: 0.2708 - val_acc: 0.7943\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.2624 - acc: 0.7973 - val_loss: 0.2505 - val_acc: 0.7971\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 8s - loss: 0.2405 - acc: 0.7969 - val_loss: 0.2284 - val_acc: 0.7970\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.2209 - acc: 0.7971 - val_loss: 0.2111 - val_acc: 0.7967\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 8s - loss: 0.2065 - acc: 0.7981 - val_loss: 0.1990 - val_acc: 0.7980\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.1956 - acc: 0.7996 - val_loss: 0.1893 - val_acc: 0.7997\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 8s - loss: 0.1867 - acc: 0.8010 - val_loss: 0.1813 - val_acc: 0.8014\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 8s - loss: 0.1793 - acc: 0.8022 - val_loss: 0.1746 - val_acc: 0.8024\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 8s - loss: 0.1731 - acc: 0.8032 - val_loss: 0.1689 - val_acc: 0.8034\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 8s - loss: 0.1677 - acc: 0.8041 - val_loss: 0.1639 - val_acc: 0.8043\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 8s - loss: 0.1630 - acc: 0.8049 - val_loss: 0.1593 - val_acc: 0.8044\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.1587 - acc: 0.8056 - val_loss: 0.1553 - val_acc: 0.8056\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.1548 - acc: 0.8063 - val_loss: 0.1515 - val_acc: 0.8062\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.1512 - acc: 0.8069 - val_loss: 0.1480 - val_acc: 0.8066\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 8s - loss: 0.1480 - acc: 0.8074 - val_loss: 0.1450 - val_acc: 0.8073\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.1450 - acc: 0.8079 - val_loss: 0.1421 - val_acc: 0.8076\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.1423 - acc: 0.8083 - val_loss: 0.1396 - val_acc: 0.8081\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.1398 - acc: 0.8087 - val_loss: 0.1371 - val_acc: 0.8083\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.1376 - acc: 0.8091 - val_loss: 0.1348 - val_acc: 0.8085\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.1354 - acc: 0.8094 - val_loss: 0.1328 - val_acc: 0.8089\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.1334 - acc: 0.8097 - val_loss: 0.1308 - val_acc: 0.8092\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.1314 - acc: 0.8100 - val_loss: 0.1288 - val_acc: 0.8095\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.1295 - acc: 0.8103 - val_loss: 0.1269 - val_acc: 0.8097\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1277 - acc: 0.8106 - val_loss: 0.1251 - val_acc: 0.8099\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.1260 - acc: 0.8108 - val_loss: 0.1234 - val_acc: 0.8102\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.1243 - acc: 0.8111 - val_loss: 0.1218 - val_acc: 0.8105\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.1227 - acc: 0.8113 - val_loss: 0.1202 - val_acc: 0.8105\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.1211 - acc: 0.8115 - val_loss: 0.1187 - val_acc: 0.8109\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1196 - acc: 0.8117 - val_loss: 0.1172 - val_acc: 0.8111\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.1182 - acc: 0.8119 - val_loss: 0.1158 - val_acc: 0.8113\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.1168 - acc: 0.8121 - val_loss: 0.1144 - val_acc: 0.8114\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.1155 - acc: 0.8123 - val_loss: 0.1132 - val_acc: 0.8115\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1143 - acc: 0.8124 - val_loss: 0.1120 - val_acc: 0.8117\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1132 - acc: 0.8125 - val_loss: 0.1109 - val_acc: 0.8118\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1121 - acc: 0.8127 - val_loss: 0.1099 - val_acc: 0.8119\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1110 - acc: 0.8128 - val_loss: 0.1089 - val_acc: 0.8120\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1101 - acc: 0.8129 - val_loss: 0.1079 - val_acc: 0.8121\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1092 - acc: 0.8130 - val_loss: 0.1071 - val_acc: 0.8122\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1084 - acc: 0.8131 - val_loss: 0.1062 - val_acc: 0.8122\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1076 - acc: 0.8131 - val_loss: 0.1055 - val_acc: 0.8123\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1069 - acc: 0.8132 - val_loss: 0.1048 - val_acc: 0.8124\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1062 - acc: 0.8133 - val_loss: 0.1042 - val_acc: 0.8125\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1056 - acc: 0.8133 - val_loss: 0.1036 - val_acc: 0.8125\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1050 - acc: 0.8134 - val_loss: 0.1030 - val_acc: 0.8125\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1045 - acc: 0.8134 - val_loss: 0.1025 - val_acc: 0.8125\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1040 - acc: 0.8135 - val_loss: 0.1020 - val_acc: 0.8126\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1035 - acc: 0.8135 - val_loss: 0.1016 - val_acc: 0.8126\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1031 - acc: 0.8135 - val_loss: 0.1012 - val_acc: 0.8127\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1027 - acc: 0.8136 - val_loss: 0.1008 - val_acc: 0.8127\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1023 - acc: 0.8136 - val_loss: 0.1004 - val_acc: 0.8128\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1019 - acc: 0.8136 - val_loss: 0.1000 - val_acc: 0.8128\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1016 - acc: 0.8137 - val_loss: 0.0997 - val_acc: 0.8128\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1012 - acc: 0.8137 - val_loss: 0.0994 - val_acc: 0.8128\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1009 - acc: 0.8137 - val_loss: 0.0991 - val_acc: 0.8128\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1007 - acc: 0.8137 - val_loss: 0.0988 - val_acc: 0.8128\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 11s - loss: 0.1004 - acc: 0.8137 - val_loss: 0.0986 - val_acc: 0.8129\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.1001 - acc: 0.8138 - val_loss: 0.0983 - val_acc: 0.8129\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.0999 - acc: 0.8138 - val_loss: 0.0981 - val_acc: 0.8129\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 11s - loss: 0.0997 - acc: 0.8138 - val_loss: 0.0979 - val_acc: 0.8129\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 11s - loss: 0.0995 - acc: 0.8138 - val_loss: 0.0977 - val_acc: 0.8129\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 11s - loss: 0.0993 - acc: 0.8138 - val_loss: 0.0975 - val_acc: 0.8129\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.0991 - acc: 0.8138 - val_loss: 0.0973 - val_acc: 0.8129\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 10s - loss: 0.0989 - acc: 0.8138 - val_loss: 0.0971 - val_acc: 0.8130\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.0987 - acc: 0.8139 - val_loss: 0.0970 - val_acc: 0.8130\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.0985 - acc: 0.8139 - val_loss: 0.0968 - val_acc: 0.8130\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.0984 - acc: 0.8139 - val_loss: 0.0967 - val_acc: 0.8130\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.0982 - acc: 0.8139 - val_loss: 0.0965 - val_acc: 0.8130\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.0981 - acc: 0.8139 - val_loss: 0.0964 - val_acc: 0.8130\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.0980 - acc: 0.8139 - val_loss: 0.0963 - val_acc: 0.8130\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.0978 - acc: 0.8139 - val_loss: 0.0962 - val_acc: 0.8130\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.0977 - acc: 0.8139 - val_loss: 0.0960 - val_acc: 0.8130\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.0976 - acc: 0.8139 - val_loss: 0.0959 - val_acc: 0.8130\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 9s - loss: 0.0975 - acc: 0.8139 - val_loss: 0.0958 - val_acc: 0.8130\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.0974 - acc: 0.8140 - val_loss: 0.0957 - val_acc: 0.8130\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 12s - loss: 0.0973 - acc: 0.8140 - val_loss: 0.0956 - val_acc: 0.8131\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 12s - loss: 0.0972 - acc: 0.8140 - val_loss: 0.0955 - val_acc: 0.8131\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 12s - loss: 0.0971 - acc: 0.8140 - val_loss: 0.0954 - val_acc: 0.8131\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 12s - loss: 0.0970 - acc: 0.8140 - val_loss: 0.0954 - val_acc: 0.8131\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 12s - loss: 0.0969 - acc: 0.8140 - val_loss: 0.0953 - val_acc: 0.8131\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 11s - loss: 0.0968 - acc: 0.8140 - val_loss: 0.0952 - val_acc: 0.8131\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.0968 - acc: 0.8140 - val_loss: 0.0951 - val_acc: 0.8131\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.0967 - acc: 0.8140 - val_loss: 0.0951 - val_acc: 0.8131\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.0966 - acc: 0.8140 - val_loss: 0.0950 - val_acc: 0.8131\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 11s - loss: 0.0965 - acc: 0.8140 - val_loss: 0.0950 - val_acc: 0.8131\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 12s - loss: 0.0965 - acc: 0.8140 - val_loss: 0.0949 - val_acc: 0.8131\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 11s - loss: 0.0964 - acc: 0.8140 - val_loss: 0.0948 - val_acc: 0.8131\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 11s - loss: 0.0963 - acc: 0.8140 - val_loss: 0.0948 - val_acc: 0.8131\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.0963 - acc: 0.8140 - val_loss: 0.0947 - val_acc: 0.8131\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.0962 - acc: 0.8140 - val_loss: 0.0947 - val_acc: 0.8131\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 11s - loss: 0.0962 - acc: 0.8140 - val_loss: 0.0946 - val_acc: 0.8131\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.0961 - acc: 0.8140 - val_loss: 0.0945 - val_acc: 0.8131\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.0961 - acc: 0.8140 - val_loss: 0.0945 - val_acc: 0.8131\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.0960 - acc: 0.8140 - val_loss: 0.0945 - val_acc: 0.8132\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.0960 - acc: 0.8141 - val_loss: 0.0944 - val_acc: 0.8132\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.0959 - acc: 0.8141 - val_loss: 0.0944 - val_acc: 0.8132\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 10s - loss: 0.0959 - acc: 0.8141 - val_loss: 0.0943 - val_acc: 0.8131\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 11s - loss: 0.0958 - acc: 0.8141 - val_loss: 0.0943 - val_acc: 0.8132\n",
      "Epoch 98/100\n",
      "28416/60000 [=============>................] - ETA: 5s - loss: 0.0960 - acc: 0.8138"
     ]
    }
   ],
   "source": [
    "autoencoder_history = autoencoder.fit(x=x_train_reshape, y=x_train_reshape,\n",
    "                                     epochs=100, batch_size=256,\n",
    "                                     shuffle=True,\n",
    "                                     validation_data=(x_test_reshape, x_test_reshape),\n",
    "                                     verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the model performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_history(network_history):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(network_history.history['loss'])\n",
    "    plt.plot(network_history.history['val_loss'])\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.plot(network_history.history['acc'])\n",
    "    plt.plot(network_history.history['val_acc'])\n",
    "    plt.legend(['Training', 'Validation'], loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "plot_history(autoencoder_history)# use Matplotlib (don't ask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstructing the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_imgs = autoencoder.predict(x_test_reshape)\n",
    "print \"Shape of reconstructed images = \", reconstructed_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(reconstructed_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
